import cv2
import numpy as np
import os 
from datetime import datetime
from PIL import Image


recognizer = cv2.face.LBPHFaceRecognizer_create() #face recognizer included on opencv package
recognizer.read('trainer/trainer.yml') #reads the yml file created at trainer.py
cascadePath = "haarcascade_frontalface_default.xml"
faceCascade = cv2.CascadeClassifier(cascadePath);

font = cv2.FONT_HERSHEY_SIMPLEX 

#iniciate id counter
id = 0
#help variable to write recognitions in txt
help_id = ''
#names related to ids: example ==> Dominik: id=1,  etc
names = ['None', 'Dominik', 'Melvin']

#Initialize and start realtime video capture
cam = cv2.VideoCapture(0)
cam.set(3, 640) # set video widht
cam.set(4, 480) # set video height

#Define min window size to be recognized as a face
minW = 0.1*cam.get(3)
minH = 0.1*cam.get(4)

def new_user(a_names):

    name = input('\n please enter your name <n> ==>  ')
    a_names.append(name)
    cam = cv2.VideoCapture(0)
    cam.set(3, 640) # set video width
    cam.set(4, 480) # set video height
    face_detector = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')
    #face_id = len(names)
    print("\n [INFO] Initializing face capture. Look the camera and wait ...") #instruction to wait

    def training(): #function for training the recognizer

        # Path for face image database
        path = 'dataset'

        # function to get all images of 'dataset' and returning 2 arrays (IDs and faces)       
        def getImagesAndLabels(path):

            imagePaths = [os.path.join(path,f) for f in os.listdir(path)]  #array for safe all paths from images
            faceSamples=[]
            ids = []

            for imagePath in imagePaths:
                PIL_img  = Image.open(imagePath).convert('L') #convert it to monochrome (einfarbig)
                img_numpy = np.array(PIL_img,'uint8') #creates an array

                id = int(os.path.split(imagePath)[-1].split(".")[1]) #get the number of saved faces 
                faces = faceCascade.detectMultiScale(img_numpy) #MultiScale detects objects of different sizes in the input image and returns rectangles positioned on the faces. 

                for (x,y,w,h) in faces: #loop through each rectangle (each face detected) using its coordinates generated by the function detectmultiscale
                    faceSamples.append(img_numpy[y:y+h,x:x+w])
                    ids.append(id) 
            return faceSamples,ids

        print ("\n [INFO] Training faces. It will take a few seconds. Wait ...")
        faces,ids = getImagesAndLabels(path)

        recognizer.train(faces, np.array(ids)) #train the recognizer with the 2 arrays of function getimagesandlabels

        # Save the model into trainer/trainer.yml
        recognizer.write('trainer/trainer.yml')
        # Print the numer of faces trained
        print("\n [INFO] {0} faces trained.".format(len(np.unique(ids))))
    count = 0
    while(True):
        ret, img = cam.read()
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) #Converts an image from one color space to another.
        faces = face_detector.detectMultiScale(gray, 1.3, 5) #Detects objects of different sizes in the input image. The detected objects are returned as a list of rectangles.
        face_id = len(names)
        for (x,y,w,h) in faces:
            cv2.rectangle(img, (x,y), (x+w,y+h), (255,0,0), 2)  #used to draw a rectangle on any image  
            count += 1
            # Save the captured image into the datasets folder
            cv2.imwrite("dataset/User." + str(face_id) + '.' + str(count) + ".jpg", gray[y:y+h,x:x+w])
            cv2.imshow('image', img)

        k = cv2.waitKey(100) & 0xff 
        if k == 27: # Press 'ESC' for exiting video
            break
        elif count >= 50: # Take 50 face sample and stop video
            break
        
    training()
    return names

while True:

    ret, img = cam.read() #reads current img of the cam

    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) #converts img to gray

    faces = faceCascade.detectMultiScale( #there to find faces
        gray,
        scaleFactor = 1.2,
        minNeighbors = 5,
        minSize = (int(minW), int(minH)),
       )

    for(x,y,w,h) in faces:

        cv2.rectangle(img, (x,y), (x+w,y+h), (0,255,0), 2) #used to draw a rectangle on any image

        id, confidence = recognizer.predict(gray[y:y+h,x:x+w]) #takes a captured portion of the face to be analyzed and returns probable owner in which he returns
                                                               #his id and a confidence with this match

        # Check if confidence is less than 60 ==> "0" is perfect match 
        if (confidence < 60):
            id = names[id]
            confidence = "  {0}%".format(round(100 - confidence))
        else:
            id = "unknown"
            confidence = "  {0}%".format(round(100 - confidence))
        
        cv2.putText(img, str(id), (x+5,y-5), font, 1, (255,255,255), 2) #prints the name over the rectangle
        cv2.putText(img, str(confidence), (x+5,y+h-5), font, 1, (255,255,0), 1)  #prints the probability under the rectangle
    
    cv2.imshow('camera',img) 
    #write data in a txt
    if help_id != id: 
        now = datetime.now() #current date and time
        d_time = now.strftime('%d. %m .%Y, %H:%M:%S') #convert datetime to a string, bc its necessary for 'write'
        file = open('data.txt', 'a')
        print(file.write(str('\n') + str(id) + ' ' + str(d_time)))
        
    help_id = id

    k = cv2.waitKey(10) & 0xFF #Press 'ESC' for exiting video and 'n' for setting a new person
    if k == 27:
        break
    elif k == ord('n'):
        cam.release()
        cv2.destroyAllWindows()
        names = new_user(names)
        
#cleanup
print("\n [INFO] Exiting Program and cleanup stuff")
cam.release()
cv2.destroyAllWindows()

#For a better percentace you need to do deep learning techniques